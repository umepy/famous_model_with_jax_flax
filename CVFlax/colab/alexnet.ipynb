{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'famous_model_with_jax_flax'...\n",
      "remote: Enumerating objects: 134, done.\u001b[K\n",
      "remote: Counting objects: 100% (134/134), done.\u001b[K\n",
      "remote: Compressing objects: 100% (77/77), done.\u001b[K\n",
      "remote: Total 134 (delta 48), reused 119 (delta 36), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (134/134), 17.65 KiB | 1.04 MiB/s, done.\n",
      "Resolving deltas: 100% (48/48), done.\n",
      "/workspaces/famous_model_with_jax_flax/CVFlax/colab/famous_model_with_jax_flax/famous_model_with_jax_flax\n",
      "Branch 'alexnet' set up to track remote branch 'alexnet' from 'origin'.\n",
      "Switched to a new branch 'alexnet'\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/umepy/famous_model_with_jax_flax.git\n",
    "%cd famous_model_with_jax_flax\n",
    "!git checkout -b alexnet origin/alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement jaxlib==0.3.15+cuda11.cudnn805; extra == \"cuda11_cudnn805\" (from jax[cuda11_cudnn805]) (from versions: 0.1.32, 0.1.40, 0.1.41, 0.1.42, 0.1.43, 0.1.44, 0.1.46, 0.1.50, 0.1.51, 0.1.52, 0.1.55, 0.1.56, 0.1.57, 0.1.58, 0.1.59, 0.1.60, 0.1.61, 0.1.62, 0.1.63, 0.1.64, 0.1.65, 0.1.66, 0.1.67, 0.1.68, 0.1.69, 0.1.70, 0.1.71, 0.1.72, 0.1.73, 0.1.74, 0.1.75, 0.1.76, 0.3.0, 0.3.2, 0.3.5, 0.3.7, 0.3.8, 0.3.10, 0.3.14, 0.3.15)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for jaxlib==0.3.15+cuda11.cudnn805; extra == \"cuda11_cudnn805\" (from jax[cuda11_cudnn805])\u001b[0m\n",
      "\u001b[31m  ERROR: Command errored out with exit status 128:\n",
      "   command: git clone -q https://github.com/google/flax.git /tmp/pip-req-build-fo20z9sy\n",
      "       cwd: None\n",
      "  Complete output (2 lines):\n",
      "  fatal: Unable to read current working directory: No such file or directory\n",
      "  fatal: remote did not send all necessary objects\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 128: git clone -q https://github.com/google/flax.git /tmp/pip-req-build-fo20z9sy Check the logs for full command output.\u001b[0m\n",
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "The folder you are executing pip from can no longer be found.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U -q pip\n",
    "!pip install -U -q jax[cuda11_cudnn805] -f https://storage.googleapis.com/jax-releases/jax_releases.html\n",
    "!pip install -U -q jaxlib optax\n",
    "!pip install -U -q git+https://github.com/google/flax.git\n",
    "!pip install -U -q torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path(os.path.abspath(\"__file__\")).parent.parent.parent))\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.tools.colab_tpu\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state, checkpoints\n",
    "\n",
    "import numpy as np\n",
    "import optax\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from CVFlax.models import AlexNet\n",
    "from CVFlax.utils.preprocess import alexnet_dataloader, download_food101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seems already being downloaded, so skipping to split dataset\n"
     ]
    }
   ],
   "source": [
    "download_food101()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(key, learning_rate):\n",
    "    params = AlexNet(output_dim=101).init(key, jnp.ones([1,227,227,3]))['params']\n",
    "    tx = optax.adam(learning_rate)\n",
    "    return train_state.TrainState.create(apply_fn=AlexNet(output_dim=101).apply, params=params, tx=tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def compute_accuracy(logits, y):\n",
    "  accuracy = jnp.mean(jnp.argmax(logits, -1) == y)\n",
    "  return accuracy\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def train_step(state, x, y):\n",
    "  def loss_fn(params):\n",
    "    logits = AlexNet(output_dim=101).apply({'params':params}, x)\n",
    "    one_hot_labels = jax.nn.one_hot(y, num_classes=101)\n",
    "    loss = jnp.mean(optax.softmax_cross_entropy(logits=logits, labels=one_hot_labels))\n",
    "    return loss, logits\n",
    "  \n",
    "  (loss, logits), grads = jax.value_and_grad(loss_fn, has_aux=True)(state.params)\n",
    "  state = state.apply_gradients(grads=grads)\n",
    "  metrics = {\n",
    "      'loss': loss,\n",
    "      'accuracy': compute_accuracy(logits, y),\n",
    "  }\n",
    "  return state, metrics\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def eval_step(state, x, y):\n",
    "  # transform x because we used FiveCrops\n",
    "  bs,ncrops,h,w,c = x.shape\n",
    "  x = x.reshape((-1,h,w,c))\n",
    "  logits = AlexNet(output_dim=101).apply({'params':state.params}, x)\n",
    "  return jnp.mean(jnp.argmax(logits.reshape(bs,ncrops, -1).mean(1), -1) == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(state, dataloader, global_step, writer):\n",
    "  batch_metrics = []\n",
    "  track_metrics = {'loss':[], 'accuracy':[]}\n",
    "  with tqdm(total=len(dataloader)) as tq:\n",
    "    for cnt, (x, y) in enumerate(dataloader):\n",
    "      tq.update(1)\n",
    "      x,y=jnp.array(x),jnp.array(y)\n",
    "      state, metrics = train_step(state, x, y) # update state \n",
    "      batch_metrics.append(metrics)\n",
    "      track_metrics['loss'].append(metrics['loss'])\n",
    "      track_metrics['accuracy'].append(metrics['accuracy'])\n",
    "\n",
    "      writer.add_scalar('train/loss', metrics['loss'].item(), global_step)\n",
    "      writer.add_scalar('train/accuracy', metrics['accuracy'].item(), global_step)\n",
    "      global_step += 1\n",
    "  \n",
    "  batch_metrics_np = jax.device_get(batch_metrics)\n",
    "  epoch_metrics_np = {\n",
    "      k: np.mean([metrics[k] for metrics in batch_metrics_np])\n",
    "      for k in batch_metrics_np[0]\n",
    "  }\n",
    "  return state, epoch_metrics_np\n",
    "\n",
    "def evaluate_epoch(state, dataloader, global_step, writer):\n",
    "  all_score = []\n",
    "  for x, y in dataloader:\n",
    "    precision = eval_step(state, x, y)\n",
    "    all_score.append(precision.item())\n",
    "  all_precision = np.mean(all_score)\n",
    "  writer.add_scalar('test/accuracy', all_precision, global_step)\n",
    "  return all_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/famous_model_with_jax_flax/CVFlax/colab/alexnet.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B623a5c70726f6a656374735c66616d6f75735f6d6f64656c5f776974685f6a61785f666c6178/workspaces/famous_model_with_jax_flax/CVFlax/colab/alexnet.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B623a5c70726f6a656374735c66616d6f75735f6d6f64656c5f776974685f6a61785f666c6178/workspaces/famous_model_with_jax_flax/CVFlax/colab/alexnet.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m drive\u001b[39m.\u001b[39mmount(\u001b[39m'\u001b[39m\u001b[39m/content/drive\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B623a5c70726f6a656374735c66616d6f75735f6d6f64656c5f776974685f6a61785f666c6178/workspaces/famous_model_with_jax_flax/CVFlax/colab/alexnet.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# paste path where you want to save model checkpoints\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# paste path where you want to save model checkpoints\n",
    "save_path = '/content/drive/My Drive/'\n",
    "\n",
    "# difine tensorboard writer\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch: 1, accuracy: 1.006\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/famous_model_with_jax_flax/CVFlax/colab/alexnet.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B623a5c70726f6a656374735c66616d6f75735f6d6f64656c5f776974685f6a61785f666c6178/workspaces/famous_model_with_jax_flax/CVFlax/colab/alexnet.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m train_loader, test_loader \u001b[39m=\u001b[39m alexnet_dataloader(batch_size\u001b[39m=\u001b[39mbatch_size)\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B623a5c70726f6a656374735c66616d6f75735f6d6f64656c5f776974685f6a61785f666c6178/workspaces/famous_model_with_jax_flax/CVFlax/colab/alexnet.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, num_epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B623a5c70726f6a656374735c66616d6f75735f6d6f64656c5f776974685f6a61785f666c6178/workspaces/famous_model_with_jax_flax/CVFlax/colab/alexnet.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m   \u001b[39m#state, train_metrics = train_epoch(state, train_loader, global_step, writer)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B623a5c70726f6a656374735c66616d6f75735f6d6f64656c5f776974685f6a61785f666c6178/workspaces/famous_model_with_jax_flax/CVFlax/colab/alexnet.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m   \u001b[39m#print(f\"Train epoch: {epoch}, loss: {train_metrics['loss']:.4}, accuracy: {train_metrics['accuracy'] * 100:.4}\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B623a5c70726f6a656374735c66616d6f75735f6d6f64656c5f776974685f6a61785f666c6178/workspaces/famous_model_with_jax_flax/CVFlax/colab/alexnet.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m   \u001b[39m#checkpoints.save_checkpoint(ckpt_dir=save_path, target=state, step=epoch, prefix='Alexnet_checkpoint_epoch_')\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://dev-container%2B623a5c70726f6a656374735c66616d6f75735f6d6f64656c5f776974685f6a61785f666c6178/workspaces/famous_model_with_jax_flax/CVFlax/colab/alexnet.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m   test_accuracy \u001b[39m=\u001b[39m evaluate_epoch(state, test_loader, global_step, writer)\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B623a5c70726f6a656374735c66616d6f75735f6d6f64656c5f776974685f6a61785f666c6178/workspaces/famous_model_with_jax_flax/CVFlax/colab/alexnet.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTest epoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m, accuracy: \u001b[39m\u001b[39m{\u001b[39;00mtest_accuracy \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.4\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/workspaces/famous_model_with_jax_flax/CVFlax/colab/alexnet.ipynb Cell 9\u001b[0m in \u001b[0;36mevaluate_epoch\u001b[0;34m(state, dataloader, global_step, writer)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B623a5c70726f6a656374735c66616d6f75735f6d6f64656c5f776974685f6a61785f666c6178/workspaces/famous_model_with_jax_flax/CVFlax/colab/alexnet.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate_epoch\u001b[39m(state, dataloader, global_step, writer):\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B623a5c70726f6a656374735c66616d6f75735f6d6f64656c5f776974685f6a61785f666c6178/workspaces/famous_model_with_jax_flax/CVFlax/colab/alexnet.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m   all_score \u001b[39m=\u001b[39m []\n\u001b[0;32m---> <a href='vscode-notebook-cell://dev-container%2B623a5c70726f6a656374735c66616d6f75735f6d6f64656c5f776974685f6a61785f666c6178/workspaces/famous_model_with_jax_flax/CVFlax/colab/alexnet.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m   \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m dataloader:\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B623a5c70726f6a656374735c66616d6f75735f6d6f64656c5f776974685f6a61785f666c6178/workspaces/famous_model_with_jax_flax/CVFlax/colab/alexnet.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     precision \u001b[39m=\u001b[39m eval_step(state, x, y)\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B623a5c70726f6a656374735c66616d6f75735f6d6f64656c5f776974685f6a61785f666c6178/workspaces/famous_model_with_jax_flax/CVFlax/colab/alexnet.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     all_score\u001b[39m.\u001b[39mappend(precision\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:1207\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1206\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1207\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1208\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1209\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1210\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:1173\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1169\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1171\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1173\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1174\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1175\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:1011\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m    999\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1011\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1012\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1013\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1014\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.9/multiprocessing/queues.py:117\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n\u001b[1;32m    116\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m--> 117\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv_bytes()\n\u001b[1;32m    118\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sem\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    119\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py:221\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[39mif\u001b[39;00m maxlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m maxlength \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    220\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mnegative maxlength\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 221\u001b[0m buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv_bytes(maxlength)\n\u001b[1;32m    222\u001b[0m \u001b[39mif\u001b[39;00m buf \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bad_message_length()\n",
      "File \u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py:426\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[39mif\u001b[39;00m maxsize \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m size \u001b[39m>\u001b[39m maxsize:\n\u001b[1;32m    425\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 426\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv(size)\n",
      "File \u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py:384\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    382\u001b[0m remaining \u001b[39m=\u001b[39m size\n\u001b[1;32m    383\u001b[0m \u001b[39mwhile\u001b[39;00m remaining \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 384\u001b[0m     chunk \u001b[39m=\u001b[39m read(handle, remaining)\n\u001b[1;32m    385\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(chunk)\n\u001b[1;32m    386\u001b[0m     \u001b[39mif\u001b[39;00m n \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "global_step = 1\n",
    "key = jax.random.PRNGKey(20220319)\n",
    "state = create_train_state(key, learning_rate)\n",
    "train_loader, test_loader = alexnet_dataloader(batch_size=batch_size)\n",
    "test_scores = []\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "  state, train_metrics = train_epoch(state, train_loader, global_step, writer)\n",
    "  print(f\"Train epoch: {epoch}, loss: {train_metrics['loss']:.4}, accuracy: {train_metrics['accuracy'] * 100:.4}\")\n",
    "\n",
    "  test_accuracy = evaluate_epoch(state, test_loader, global_step, writer)\n",
    "  print(f\"Test epoch: {epoch}, accuracy: {test_accuracy * 100:.4}\")\n",
    "\n",
    "  if test_scores==[] or test_accuracy > test_scores[-1]:\n",
    "    checkpoints.save_checkpoint(ckpt_dir=save_path, target=state, step=epoch, prefix='Alexnet_checkpoint_epoch_')\n",
    "  test_scores.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "global_step = 1\n",
    "key = jax.random.PRNGKey(20220319)\n",
    "state = create_train_state(key, learning_rate)\n",
    "train_loader, test_loader = alexnet_dataloader(batch_size=batch_size)\n",
    "for x,y in test_loader:\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
