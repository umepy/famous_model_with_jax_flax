{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/umepy/famous_model_with_jax_flax.git\n",
    "%cd famous_model_with_jax_flax\n",
    "!git checkout -b alexnet origin/alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q pip optax flax\n",
    "!pip install -U torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path(os.path.abspath(\"__file__\")).parent.parent.parent))\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.tools.colab_tpu\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "\n",
    "import numpy as np\n",
    "import optax\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from CVFlax.models import AlexNet\n",
    "from CVFlax.utils.preprocess import alexnet_dataloader, download_food101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seems already splitted, so skipping to split dataset\n"
     ]
    }
   ],
   "source": [
    "download_food101()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(key, learning_rate):\n",
    "    params = AlexNet(output_dim=101).init(key, jnp.ones([1,227,227,3]))['params']\n",
    "    tx = optax.adam(learning_rate)\n",
    "    return train_state.TrainState.create(apply_fn=AlexNet(output_dim=101).apply, params=params, tx=tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def compute_accuracy(logits, y):\n",
    "  accuracy = jnp.mean(jnp.argmax(logits, -1) == y)\n",
    "  return accuracy\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def train_step(state, x, y):\n",
    "  def loss_fn(params):\n",
    "    logits = AlexNet(output_dim=101).apply({'params':params}, x)\n",
    "    one_hot_labels = jax.nn.one_hot(y, num_classes=101)\n",
    "    loss = jnp.mean(optax.softmax_cross_entropy(logits=logits, labels=one_hot_labels))\n",
    "    return loss, logits\n",
    "  \n",
    "  (loss, logits), grads = jax.value_and_grad(loss_fn, has_aux=True)(state.params)\n",
    "  state = state.apply_gradients(grads=grads)\n",
    "  metrics = {\n",
    "      'loss': loss,\n",
    "      'accuracy': compute_accuracy(logits, y),\n",
    "  }\n",
    "  return state, metrics\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def eval_step(state, x, y):\n",
    "  logits = AlexNet().apply({'params':state.params}, x)\n",
    "  return compute_accuracy(logits, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(state, dataloader, epoch):\n",
    "  batch_metrics = []\n",
    "  track_metrics = {'loss':[], 'accuracy':[]}\n",
    "  with tqdm(total=len(dataloader)) as tq:\n",
    "    for cnt, (x, y) in enumerate(dataloader):\n",
    "      tq.update(1)\n",
    "      state, metrics = train_step(state, x, y) # update state \n",
    "      batch_metrics.append(metrics)\n",
    "      track_metrics['loss'].append(metrics['loss'])\n",
    "      track_metrics['accuracy'].append(metrics['accuracy'])\n",
    "\n",
    "      if cnt%20==0:\n",
    "        print(f'Epoch: {cnt}\\tloss: {np.mean(track_metrics[\"loss\"])}\\taccuracy: {np.mean(track_metrics[\"accuracy\"])}')\n",
    "        track_metrics = {'loss':[], 'accuracy':[]}\n",
    "  \n",
    "  batch_metrics_np = jax.device_get(batch_metrics)\n",
    "  epoch_metrics_np = {\n",
    "      k: np.mean([metrics[k] for metrics in batch_metrics_np])\n",
    "      for k in batch_metrics_np[0]\n",
    "  }\n",
    "  return state, epoch_metrics_np\n",
    "\n",
    "\n",
    "def evaluate_model(state, x, y):\n",
    "  metrics = eval_step(state, x, y)\n",
    "  metrics = jax.device_get(metrics)\n",
    "  metrics = jax.tree_map(lambda x: x.item(), metrics)  # np.ndarray -> scalar\n",
    "  return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "key = jax.random.PRNGKey(20220319)\n",
    "state = create_train_state(key, learning_rate)\n",
    "train_loader, test_loader = alexnet_dataloader(batch_size=batch_size)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "  state, train_metrics = train_epoch(state, train_loader, epoch)\n",
    "  print(f\"Train epoch: {epoch}, loss: {train_metrics['loss']:.4}, accuracy: {train_metrics['accuracy'] * 100:.4}\")\n",
    "\n",
    "\n",
    "  #test_metrics = eval_step(state, test_images, test_lbls)\n",
    "  #print(f\"Test epoch: {epoch}, accuracy: {test_metrics * 100:.4}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
